import tensorflow as tf
import cv2
import numpy as np
import face_recognition
from flask import Flask, render_template, Response, jsonify, request
import os
import threading

app = Flask(__name__)

COCO_LABELS = [
    'background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
    'traffic light', 'fire hydrant', 'none', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',
    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'none', 'backpack', 'umbrella', 'none', 'handbag', 'tie',
    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',
    'surfboard', 'tennis racket', 'bottle', 'none', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',
    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',
    'bed', 'dining table', 'toilet', 'none', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',
    'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]

model = tf.saved_model.load('/home/pi/ai/ssd_mobilenet_v2_coco_2018_03_29/saved_model')
detect_fn = model.signatures['serving_default']

cap = cv2.VideoCapture(0)

known_face_encodings = []
known_face_names = []
known_images_directory = "/home/pi/ai/dataset"

for person_name in os.listdir(known_images_directory):
    person_folder = os.path.join(known_images_directory, person_name)
    if os.path.isdir(person_folder):
        for image_name in os.listdir(person_folder):
            image_path = os.path.join(person_folder, image_name)
            known_image = face_recognition.load_image_file(image_path)
            encoding = face_recognition.face_encodings(known_image)
            if encoding:
                known_face_encodings.append(encoding[0])
                known_face_names.append(person_name)

@app.route('/detections')
def detections():
    ret, frame = cap.read()
    if not ret:
        return jsonify([])

    input_tensor = tf.convert_to_tensor(frame)
    input_tensor = input_tensor[tf.newaxis, ...]
    detections = detect_fn(input_tensor)

    boxes = detections['detection_boxes'].numpy()
    class_ids = detections['detection_classes'].numpy().astype(np.int32)
    scores = detections['detection_scores'].numpy()

    objects_detected = []

    num_boxes = boxes.shape[1]
    for i in range(num_boxes):
        if scores[0][i] > 0.5:
            label = COCO_LABELS[class_ids[0][i]] if 0 < class_ids[0][i] < len(COCO_LABELS) else 'Unknown'
            objects_detected.append(label)

    face_locations = face_recognition.face_locations(frame)
    face_encodings = face_recognition.face_encodings(frame, face_locations)

    for _, face_encoding in zip(face_locations, face_encodings):
        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
        name = "Unknown"
        if True in matches:
            first_match_index = matches.index(True)
            name = known_face_names[first_match_index]
        objects_detected.append(f"Face: {name}")

    return jsonify(objects_detected)

def generate_video_feed():
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        _, buffer = cv2.imencode('.jpg', frame)
        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

@app.route('/')
def index():
    return render_template('index1.html')

@app.route('/capture_image', methods=['GET'])
def capture_image():
    folder_name = request.args.get('folder_name')
    
    if not folder_name:
        return jsonify({'message': 'No folder name provided'}), 400
    
    folder_path = os.path.join(known_images_directory, folder_name)
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
    
    ret, frame = cap.read()
    if not ret:
        return jsonify({'message': 'Failed to capture image'}), 500
    
    image_path = os.path.join(folder_path, 'image.jpg')
    cv2.imwrite(image_path, frame)
    
    known_face_encodings.clear()
    known_face_names.clear()

    for person_name in os.listdir(known_images_directory):
        person_folder = os.path.join(known_images_directory, person_name)
        if os.path.isdir(person_folder):
            for image_name in os.listdir(person_folder):
                image_path = os.path.join(person_folder, image_name)
                known_image = face_recognition.load_image_file(image_path)
                encoding = face_recognition.face_encodings(known_image)
                if encoding:
                    known_face_encodings.append(encoding[0])
                    known_face_names.append(person_name)
    
    return jsonify({'message': f'Image saved successfully in folder "{folder_name}" as image.jpg and dataset updated'})


@app.route('/video_feed1')
def video_feed1():
    return Response(generate_video_feed(), mimetype='multipart/x-mixed-replace; boundary=frame')


@app.route('/video_feed')
def video_feed():
    detection_results = {"boxes": None, "class_ids": None, "scores": None}
    lock = threading.Lock() 

    def detection_thread():
        """Thread to handle detection independently."""
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            small_frame = cv2.resize(frame, (640, 480))
            input_tensor = tf.convert_to_tensor(small_frame)
            input_tensor = input_tensor[tf.newaxis, ...]

            detections = detect_fn(input_tensor)

            with lock:
                detection_results["boxes"] = detections['detection_boxes'].numpy()
                detection_results["class_ids"] = detections['detection_classes'].numpy().astype(np.int32)
                detection_results["scores"] = detections['detection_scores'].numpy()

    threading.Thread(target=detection_thread, daemon=True).start()

    def gen():
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            with lock:
                if detection_results["boxes"] is not None:
                    boxes = detection_results["boxes"]
                    class_ids = detection_results["class_ids"]
                    scores = detection_results["scores"]

                    num_boxes = boxes.shape[1]
                    for i in range(num_boxes):
                        if scores[0][i] > 0.3:  # Confidence threshold
                            ymin, xmin, ymax, xmax = boxes[0][i]
                            (startX, startY, endX, endY) = (
                                int(xmin * frame.shape[1]), int(ymin * frame.shape[0]),
                                int(xmax * frame.shape[1]), int(ymax * frame.shape[0])
                            )
                            class_id = class_ids[0][i]
                            label = COCO_LABELS[class_id] if 0 < class_id < len(COCO_LABELS) else 'Unknown'
                            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)
                            cv2.putText(frame, f'{label} {scores[0][i]:.2f}', (startX, startY - 10),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            _, buffer = cv2.imencode('.jpg', frame)
            yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')

    return Response(gen(), mimetype='multipart/x-mixed-replace; boundary=frame')


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, threaded=True)
